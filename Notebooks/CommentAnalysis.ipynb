{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install\n",
    "\n",
    "**This lines from SpaCy's docs** https://spacy.io/usage\n",
    "\n",
    "pip install -U spacy\n",
    "\n",
    "or **conda**\n",
    "\n",
    "conda install -c conda-forge spacy\n",
    "\n",
    "I used this (md) because have more data than the (sm)\n",
    "\n",
    "python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train dataset url\n",
    "\n",
    "## https://www.kaggle.com/c/tweet-sentiment-extraction/data?select=train.csv\n",
    "\n",
    "## useful links\n",
    "\n",
    "## https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/\n",
    "## https://towardsdatascience.com/machine-learning-for-text-classification-using-spacy-in-python-b276b4051a49\n",
    "## https://www.kaggle.com/poonaml/text-classification-using-spacy\n",
    "\n",
    "# Loading train dataset\n",
    "dataset_train = pd.read_csv('../Data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>4eac33d1c0</td>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>d lost</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>4f4c4fc327</td>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>, don`t force</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>f67aae2310</td>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>Yay good for both of you.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>ed167662a5</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>6f7127d9d7</td>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "      <td>All this flirting going on - The ATG smiles. Y...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "0      cb774db0d1                I`d have responded, if I were going   \n",
       "1      549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2      088c60f138                          my boss is bullying me...   \n",
       "3      9642c003ef                     what interview! leave me alone   \n",
       "4      358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "...           ...                                                ...   \n",
       "27476  4eac33d1c0   wish we could come see u on Denver  husband l...   \n",
       "27477  4f4c4fc327   I`ve wondered about rake to.  The client has ...   \n",
       "27478  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n",
       "27479  ed167662a5                         But it was worth it  ****.   \n",
       "27480  6f7127d9d7     All this flirting going on - The ATG smiles...   \n",
       "\n",
       "                                           selected_text sentiment  \n",
       "0                    I`d have responded, if I were going   neutral  \n",
       "1                                               Sooo SAD  negative  \n",
       "2                                            bullying me  negative  \n",
       "3                                         leave me alone  negative  \n",
       "4                                          Sons of ****,  negative  \n",
       "...                                                  ...       ...  \n",
       "27476                                             d lost  negative  \n",
       "27477                                      , don`t force  negative  \n",
       "27478                          Yay good for both of you.  positive  \n",
       "27479                         But it was worth it  ****.  positive  \n",
       "27480  All this flirting going on - The ATG smiles. Y...   neutral  \n",
       "\n",
       "[27481 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     11118\n",
       "positive     8582\n",
       "negative     7781\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifying quantity of each category\n",
    "dataset_train.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return 0 if negative and 1 if positive and 2 if neutral\n",
    "def convert_sentiment(x):\n",
    "    if x == 'negative':\n",
    "        return 0\n",
    "    elif x == 'positive':\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train2 = dataset_train\n",
    "dataset_train2['sentiment'] = dataset_train2['sentiment'].apply(convert_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies to each row (lambda with axis=1) and get two columns, text and sentiment, concat this two values and put then in a\n",
    "#  new column in the dataset, called tuples\n",
    "dataset_train2['tuples'] = dataset_train2.apply(\n",
    "    lambda row: (row['text'],row['sentiment']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tuples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>2</td>\n",
       "      <td>( I`d have responded, if I were going, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>0</td>\n",
       "      <td>( Sooo SAD I will miss you here in San Diego!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>0</td>\n",
       "      <td>(my boss is bullying me..., 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>0</td>\n",
       "      <td>( what interview! leave me alone, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>0</td>\n",
       "      <td>( Sons of ****, why couldn`t they put them on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>4eac33d1c0</td>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>d lost</td>\n",
       "      <td>0</td>\n",
       "      <td>( wish we could come see u on Denver  husband ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>4f4c4fc327</td>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>, don`t force</td>\n",
       "      <td>0</td>\n",
       "      <td>( I`ve wondered about rake to.  The client has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>f67aae2310</td>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>Yay good for both of you.</td>\n",
       "      <td>1</td>\n",
       "      <td>( Yay good for both of you. Enjoy the break - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>ed167662a5</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>1</td>\n",
       "      <td>( But it was worth it  ****., 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>6f7127d9d7</td>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "      <td>All this flirting going on - The ATG smiles. Y...</td>\n",
       "      <td>2</td>\n",
       "      <td>(   All this flirting going on - The ATG smile...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "0      cb774db0d1                I`d have responded, if I were going   \n",
       "1      549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2      088c60f138                          my boss is bullying me...   \n",
       "3      9642c003ef                     what interview! leave me alone   \n",
       "4      358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "...           ...                                                ...   \n",
       "27476  4eac33d1c0   wish we could come see u on Denver  husband l...   \n",
       "27477  4f4c4fc327   I`ve wondered about rake to.  The client has ...   \n",
       "27478  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n",
       "27479  ed167662a5                         But it was worth it  ****.   \n",
       "27480  6f7127d9d7     All this flirting going on - The ATG smiles...   \n",
       "\n",
       "                                           selected_text  sentiment  \\\n",
       "0                    I`d have responded, if I were going          2   \n",
       "1                                               Sooo SAD          0   \n",
       "2                                            bullying me          0   \n",
       "3                                         leave me alone          0   \n",
       "4                                          Sons of ****,          0   \n",
       "...                                                  ...        ...   \n",
       "27476                                             d lost          0   \n",
       "27477                                      , don`t force          0   \n",
       "27478                          Yay good for both of you.          1   \n",
       "27479                         But it was worth it  ****.          1   \n",
       "27480  All this flirting going on - The ATG smiles. Y...          2   \n",
       "\n",
       "                                                  tuples  \n",
       "0              ( I`d have responded, if I were going, 2)  \n",
       "1      ( Sooo SAD I will miss you here in San Diego!!...  \n",
       "2                         (my boss is bullying me..., 0)  \n",
       "3                   ( what interview! leave me alone, 0)  \n",
       "4      ( Sons of ****, why couldn`t they put them on ...  \n",
       "...                                                  ...  \n",
       "27476  ( wish we could come see u on Denver  husband ...  \n",
       "27477  ( I`ve wondered about rake to.  The client has...  \n",
       "27478  ( Yay good for both of you. Enjoy the break - ...  \n",
       "27479                   ( But it was worth it  ****., 1)  \n",
       "27480  (   All this flirting going on - The ATG smile...  \n",
       "\n",
       "[27481 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formating the new column to list type\n",
    "train = dataset_train2['tuples'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' I`d have responded, if I were going', 2),\n",
       " (' Sooo SAD I will miss you here in San Diego!!!', 0),\n",
       " ('my boss is bullying me...', 0),\n",
       " (' what interview! leave me alone', 0),\n",
       " (' Sons of ****, why couldn`t they put them on the releases we already bought',\n",
       "  0)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using list comprehension to use only 'negative' or 'positive' comments (0 or 1) (False or True)\n",
    "train2 = [item for item in train if item[1] != 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' Sooo SAD I will miss you here in San Diego!!!', 0),\n",
       " ('my boss is bullying me...', 0),\n",
       " (' what interview! leave me alone', 0),\n",
       " (' Sons of ****, why couldn`t they put them on the releases we already bought',\n",
       "  0),\n",
       " ('2am feedings for the baby are fun when he is all smiles and coos', 1)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions from spacy docs\n",
    "\n",
    "https://spacy.io/usage/examples\n",
    "\n",
    "Block **Training spaCy's text classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(limit=0, split=0.7):\n",
    "    train_data = train2\n",
    "    np.random.shuffle(train_data)\n",
    "    train_data = train_data[-limit:]\n",
    "    texts, labels = zip(*train_data)\n",
    "    cats = [{\"POSITIVE\": bool(y)} for y in labels]\n",
    "    split = int(len(train_data) * split)\n",
    "    return (texts[:split], cats[:split]), (texts[split:], cats[split:])\n",
    "\n",
    "def evaluate(tokenizer, textcat, texts, cats):\n",
    "    docs = (tokenizer(text) for text in texts)\n",
    "    tp = 1e-8  # True positives\n",
    "    fp = 1e-8  # False positives\n",
    "    fn = 1e-8  # False negatives\n",
    "    tn = 1e-8  # True negatives\n",
    "    for i, doc in enumerate(textcat.pipe(docs)):\n",
    "        gold = cats[i]\n",
    "        for label, score in doc.cats.items():\n",
    "            if label not in gold:\n",
    "                continue\n",
    "            if score >= 0.5 and gold[label] >= 0.5:\n",
    "                tp += 1.\n",
    "            elif score >= 0.5 and gold[label] < 0.5:\n",
    "                fp += 1.\n",
    "            elif score < 0.5 and gold[label] < 0.5:\n",
    "                tn += 1\n",
    "            elif score < 0.5 and gold[label] >= 0.5:\n",
    "                fn += 1\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return {'textcat_p': precision, 'textcat_r': recall, 'textcat_f': f_score}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SpaCy to analize the comments\n",
    "\n",
    "**Command:** python -m spacy download en_core_web_md\n",
    "\n",
    "Reference: https://spacy.io/usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code from https://www.kaggle.com/poonaml/text-classification-using-spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the text classifier to the pipeline if it doesn't exist\n",
    "# nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "if 'textcat' not in nlp.pipe_names:\n",
    "    textcat = nlp.create_pipe('textcat')\n",
    "    nlp.add_pipe(textcat, last=True)\n",
    "# otherwise, get it, so we can add labels to it\n",
    "else:\n",
    "    textcat = nlp.get_pipe('textcat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add label to text classifier\n",
    "textcat.add_label('POSITIVE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the train and test1 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test1 because this first test is using the dataset of the Twitter, after that, I'll use the real data, from YouTube comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vars from SpaCy's docs\n",
    "n_texts=10000 # \"Number of texts to train from\", \"option\", \"t\", int\n",
    "n_iter=15 #\"Number of training iterations\", \"option\", \"n\", int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Using 10000 examples (7000 training, 3000 evaluation)\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "(train_texts, train_cats), (dev_texts, dev_cats) = load_data(limit=n_texts)\n",
    "\n",
    "print(\"Using {} examples ({} training, {} evaluation)\"\n",
    "     .format(n_texts, len(train_texts), len(dev_texts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list(zip(train_texts, [{'cats': cats} for cats in train_cats]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the new data\n",
    "\n",
    "Now, the classes of our data is POSITIVE: True or POSITIVE: False\n",
    "\n",
    "True by Positive phrase\n",
    "\n",
    "False by Negative phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('He is so silly.  http://twitpic.com/4jk6b', {'cats': {'POSITIVE': False}}),\n",
       " ('ok, back to the dentist today. All I want to do is bask in the sun',\n",
       "  {'cats': {'POSITIVE': True}}),\n",
       " (' Hi bunny! I recently have subcribed to your channel on YouTube! You make some great stuff. Kinda just wanted to say hi!',\n",
       "  {'cats': {'POSITIVE': True}}),\n",
       " ('well.. all my slacking off earned me a D and a C   but at least everything else are A`s and B`s ^^  next school year all B`s and A`s Esh!',\n",
       "  {'cats': {'POSITIVE': True}}),\n",
       " (' iknowww! Not many people know about it tho. So I like to keep it my little secret',\n",
       "  {'cats': {'POSITIVE': True}})]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block is from Spacy's Docs https://spacy.io/usage/examples\n",
    "\n",
    "And some lines were modified in https://www.kaggle.com/poonaml/text-classification-using-spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.util import minibatch, compounding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small Explanation\n",
    "\n",
    "The SpaCy's text classifier uses multi-label convelutional neural network, and the training can take a lot of time.\n",
    "\n",
    "The variable **n_iter** means the quantity of times that used in the training loop, so, big numbers means a lot of time.\n",
    "\n",
    "Everything depends the size of your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "LOSS \t  P  \t  R  \t  F  \n",
      "6.494\t0.898\t0.875\t0.886\n",
      "3.426\t0.905\t0.890\t0.898\n",
      "2.444\t0.908\t0.909\t0.908\n",
      "1.959\t0.907\t0.902\t0.905\n",
      "1.573\t0.907\t0.894\t0.900\n",
      "1.306\t0.902\t0.899\t0.901\n",
      "0.958\t0.905\t0.893\t0.899\n",
      "0.778\t0.900\t0.893\t0.896\n",
      "0.789\t0.900\t0.891\t0.895\n",
      "0.658\t0.895\t0.888\t0.892\n",
      "0.571\t0.889\t0.888\t0.889\n",
      "0.527\t0.886\t0.881\t0.884\n",
      "0.482\t0.890\t0.874\t0.882\n",
      "0.358\t0.888\t0.878\t0.883\n",
      "0.351\t0.889\t0.878\t0.883\n",
      "0.396\t0.883\t0.881\t0.882\n",
      "0.410\t0.885\t0.883\t0.884\n",
      "0.301\t0.886\t0.881\t0.883\n",
      "0.353\t0.886\t0.883\t0.884\n",
      "0.307\t0.888\t0.882\t0.885\n"
     ]
    }
   ],
   "source": [
    "# get names of other pipes to disable them during training\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'textcat']\n",
    "with nlp.disable_pipes(*other_pipes):  # only train textcat\n",
    "    optimizer = nlp.begin_training()\n",
    "    print(\"Training the model...\")\n",
    "    print('{:^5}\\t{:^5}\\t{:^5}\\t{:^5}'.format('LOSS', 'P', 'R', 'F'))\n",
    "    for i in range(n_iter):\n",
    "        losses = {}\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        batches = minibatch(train_data, size=compounding(4., 32., 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(texts, annotations, sgd=optimizer, drop=0.2,\n",
    "                       losses=losses)\n",
    "        with textcat.model.use_params(optimizer.averages):\n",
    "            # evaluate on the dev data split off in load_data()\n",
    "            scores = evaluate(nlp.tokenizer, textcat, dev_texts, dev_cats)\n",
    "        print('{0:.3f}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}'  # print a simple table\n",
    "              .format(losses['textcat'], scores['textcat_p'],\n",
    "                      scores['textcat_r'], scores['textcat_f']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More explanation\n",
    "\n",
    "The algorithm above print some information\n",
    "\n",
    "LOSS, P, R, F\n",
    "\n",
    "**LOSS** - This value we can see as the erros of our model\n",
    "\n",
    "**P means precision**\n",
    "\n",
    "- Precision is the ratio of correctly predicted positive observations to the total predicted positive observations.\n",
    " - **Example:** Of all passengers that labeled as survived, how many actually survived?\n",
    " - TruePositives / (TruePositives + FalsePositives)\n",
    " \n",
    "**R means Recall** (like a sensitivity)\n",
    "- Recall is the ratio of correctly predicted positive observations to the all observations in actual class - yes.\n",
    " - **Example:** Of all the passengers that truly survived, how many did we label?\n",
    " - TruePositives / (TruePositives + FalseNegatives)\n",
    " \n",
    "**F means F-Score** \n",
    "- F-score is the weighted average of Precision and Recall. This option can exclude the possibility of an excellent precision with a terrible recall, or, a terrible precision with an excellent recall. This provides a way to express both concerns with a single score.\n",
    " - F-Score = 2*(Recall * Precision) / (Recall + Precision)\n",
    " \n",
    "Our values to P, R and F is good, 0.88\n",
    " \n",
    "\n",
    "#### References\n",
    "- https://machinelearningmastery.com/precision-recall-and-f-measure-for-imbalanced-classification/#:~:text=Precision%20quantifies%20the%20number%20of,and%20recall%20in%20one%20number.\n",
    "- https://blog.exsilio.com/all/accuracy-precision-recall-f1-score-interpretation-of-performance-measures/\n",
    "- https://medium.com/@vilsonrodrigues/machine-learning-o-que-s%C3%A3o-acurracy-precision-recall-e-f1-score-f16762f165b0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to D:\\backup\\Documentos\\PROGRAMACAO\\InteligenciaArtificial\\NLP\\YouTubeNPL\\Notebooks\n"
     ]
    }
   ],
   "source": [
    "output_dir=%pwd\n",
    "nlp.to_disk(output_dir)\n",
    "print(\"Saved model to\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from D:\\backup\\Documentos\\PROGRAMACAO\\InteligenciaArtificial\\NLP\\YouTubeNPL\\Notebooks\n"
     ]
    }
   ],
   "source": [
    "# Test the saved model\n",
    "print(\"Loading from\", output_dir)\n",
    "nlp2 = spacy.load(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Its time to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading comments dataset\n",
    "dataset = pd.read_csv('../Data/EuroPython Conference/comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = list(dataset['Comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Nice, very \"complete\" talk. I\\'d like to mention a very recent CLI package I created though called cliche. You can find out more about it here https://github.com/kootenpv/cliche',\n",
       " {'POSITIVE': 0.9899575114250183})"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp2(comments[2])\n",
    "comments[2], doc.cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result close to 1 is a **positive** classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"That's really pathetic.\", {'POSITIVE': 0.0014924798160791397})"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp2(comments[12])\n",
    "comments[12], doc.cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result close to 0 is a **negative** classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MISSION COMPLETE\n",
    "\n",
    "**For while**\n",
    "\n",
    "#### Observations\n",
    "\n",
    "- We got **0.88** in Precision, Recall and F-Score, but this number **could be better** if the data was treated, because could used some tecniques to adjust the text to improve accuracy of the model (this can be made in the future versions)\n",
    "- This project uses the english language and could be converted to **another languages** easily\n",
    "- This is the **first version** of the project, so has a lot of things can be improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ambiente_sofia",
   "language": "python",
   "name": "ambiente_sofia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
